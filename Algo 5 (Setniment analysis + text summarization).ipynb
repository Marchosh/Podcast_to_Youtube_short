{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc12525f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Start     End                                      Text\n",
      "0  0.000   5.339  welcome to mortgage Mondays Today's Show\n",
      "1  2.280   6.720    we are going to break down an FHA loan\n",
      "2  5.339   8.280     pretty much everything that you could\n",
      "3  6.720   9.720      possibly need to know but if you now\n",
      "4  8.280  10.980   show up to an appointment with the loan\n"
     ]
    }
   ],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def get_youtube_video_transcript_dataframe(youtube_url):\n",
    "    try:\n",
    "        # Extract video ID from the URL\n",
    "        video_id = youtube_url.split(\"v=\")[-1]\n",
    "\n",
    "        # Get the transcript\n",
    "        transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "\n",
    "        # Create an empty list to store the transcript data\n",
    "        transcript_data = []\n",
    "\n",
    "        # Loop through each transcript item and extract timestamp and text\n",
    "        for item in transcript:\n",
    "            start_time = item[\"start\"]\n",
    "            end_time = item[\"start\"] + item[\"duration\"]\n",
    "            text = item[\"text\"]\n",
    "            transcript_data.append({\"Start\": start_time, \"End\": end_time, \"Text\": text})\n",
    "\n",
    "        # Convert the list to a pandas DataFrame\n",
    "        df = pd.DataFrame(transcript_data)\n",
    "\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "        return None\n",
    "\n",
    "# Replace the following with the YouTube video URL of your choice\n",
    "youtube_url = \"https://www.youtube.com/watch?v=VyFk2sdw230&ab_channel=BiggerPockets\"\n",
    "transcript_df = get_youtube_video_transcript_dataframe(youtube_url)\n",
    "\n",
    "if transcript_df is not None:\n",
    "    print(transcript_df.head())\n",
    "else:\n",
    "    print(\"Failed to get the transcript.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e4de3f",
   "metadata": {},
   "source": [
    "# Preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6643709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000</td>\n",
       "      <td>5.339</td>\n",
       "      <td>welcome to mortgage Mondays Today's Show</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.280</td>\n",
       "      <td>6.720</td>\n",
       "      <td>we are going to break down an FHA loan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.339</td>\n",
       "      <td>8.280</td>\n",
       "      <td>pretty much everything that you could</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.720</td>\n",
       "      <td>9.720</td>\n",
       "      <td>possibly need to know but if you now</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.280</td>\n",
       "      <td>10.980</td>\n",
       "      <td>show up to an appointment with the loan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Start     End                                      Text\n",
       "0  0.000   5.339  welcome to mortgage Mondays Today's Show\n",
       "1  2.280   6.720    we are going to break down an FHA loan\n",
       "2  5.339   8.280     pretty much everything that you could\n",
       "3  6.720   9.720      possibly need to know but if you now\n",
       "4  8.280  10.980   show up to an appointment with the loan"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3f460ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 517 entries, 0 to 516\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Start   517 non-null    float64\n",
      " 1   End     517 non-null    float64\n",
      " 2   Text    517 non-null    object \n",
      "dtypes: float64(2), object(1)\n",
      "memory usage: 12.2+ KB\n"
     ]
    }
   ],
   "source": [
    "transcript_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfc5282",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5b199ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "data = transcript_df\n",
    "\n",
    "model_name = 'bert-base-uncased'\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=3)\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "# Preprocess text and tokenize\n",
    "def preprocess_text(text):\n",
    "    return \" \".join(text.split())  # Remove extra spaces\n",
    "\n",
    "data['Text'] = data['Text'].apply(preprocess_text)\n",
    "inputs = tokenizer(data['Text'].tolist(), padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "# Perform sentiment analysis\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    probs = softmax(outputs.logits, dim=1).numpy()  # Convert logits to probabilities\n",
    "\n",
    "# Add sentiment labels and probabilities to the dataframe\n",
    "sentiment_labels = ['negative', 'neutral', 'positive']\n",
    "data['Sentiment'] = [sentiment_labels[p.argmax()] for p in probs]\n",
    "data[['NegativeProb', 'NeutralProb', 'PositiveProb']] = pd.DataFrame(probs, columns=sentiment_labels)\n",
    "\n",
    "# Save the modified dataset\n",
    "data.to_csv('sentiment_analysis_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f85b382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>NegativeProb</th>\n",
       "      <th>NeutralProb</th>\n",
       "      <th>PositiveProb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000</td>\n",
       "      <td>5.339</td>\n",
       "      <td>welcome to mortgage Mondays Today's Show</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.501745</td>\n",
       "      <td>0.219033</td>\n",
       "      <td>0.279222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.280</td>\n",
       "      <td>6.720</td>\n",
       "      <td>we are going to break down an FHA loan</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.468423</td>\n",
       "      <td>0.231924</td>\n",
       "      <td>0.299653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.339</td>\n",
       "      <td>8.280</td>\n",
       "      <td>pretty much everything that you could</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.428133</td>\n",
       "      <td>0.217805</td>\n",
       "      <td>0.354062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.720</td>\n",
       "      <td>9.720</td>\n",
       "      <td>possibly need to know but if you now</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.420645</td>\n",
       "      <td>0.250991</td>\n",
       "      <td>0.328365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.280</td>\n",
       "      <td>10.980</td>\n",
       "      <td>show up to an appointment with the loan</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.474714</td>\n",
       "      <td>0.224691</td>\n",
       "      <td>0.300596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Start     End                                      Text Sentiment  \\\n",
       "0  0.000   5.339  welcome to mortgage Mondays Today's Show  negative   \n",
       "1  2.280   6.720    we are going to break down an FHA loan  negative   \n",
       "2  5.339   8.280     pretty much everything that you could  negative   \n",
       "3  6.720   9.720      possibly need to know but if you now  negative   \n",
       "4  8.280  10.980   show up to an appointment with the loan  negative   \n",
       "\n",
       "   NegativeProb  NeutralProb  PositiveProb  \n",
       "0      0.501745     0.219033      0.279222  \n",
       "1      0.468423     0.231924      0.299653  \n",
       "2      0.428133     0.217805      0.354062  \n",
       "3      0.420645     0.250991      0.328365  \n",
       "4      0.474714     0.224691      0.300596  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036a6e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------example\n",
    "\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "from moviepy.editor import VideoFileClip, concatenate_videoclips\n",
    "\n",
    "# Initialize the sentiment analyzer\n",
    "nltk.download('vader_lexicon')\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Load a pre-trained model for summarization\n",
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')\n",
    "model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')\n",
    "\n",
    "def analyze_sentiment(text):\n",
    "    \"\"\"\n",
    "    Analyze the sentiment of a text and return the sentiment score.\n",
    "    \"\"\"\n",
    "    sentiment_score = sia.polarity_scores(text)['compound']\n",
    "    return sentiment_score\n",
    "\n",
    "def filter_sentences_by_sentiment(transcript, threshold=0.2):\n",
    "    \"\"\"\n",
    "    Filter sentences from the transcript based on a sentiment threshold.\n",
    "    It filters both positive and negative sentences and leaves out neutral ones.\n",
    "    \"\"\"\n",
    "    significant_sentences = [\n",
    "        (start, end, sentence) for start, end, sentence in transcript\n",
    "        if abs(analyze_sentiment(sentence)) >= threshold\n",
    "    ]\n",
    "    return significant_sentences\n",
    "\n",
    "# ... (Other functions remain the same)\n",
    "\n",
    "# Sample YouTube transcript with timestamps (start_time, end_time, sentence)\n",
    "transcript = [\n",
    "    (0, 5, \"This is an amazing discovery.\"),\n",
    "    (6, 10, \"It changes everything we knew about space.\"),\n",
    "    (11, 20, \"Regular maintenance is scheduled for next week.\"),\n",
    "    (21, 30, \"Breaking news about the situation unfolding downtown.\")\n",
    "]\n",
    "\n",
    "# Filter sentences by sentiment (excluding neutral in this case)\n",
    "filtered_transcript = filter_sentences_by_sentiment(transcript, threshold=0.2)\n",
    "\n",
    "# Generate a summary of the filtered transcript\n",
    "transcript_text = ' '.join(sentence for _, _, sentence in filtered_transcript)\n",
    "summary = summarize_text(transcript_text)\n",
    "\n",
    "# Extract timestamps corresponding to the summary\n",
    "timestamps = extract_timestamps(summary, filtered_transcript)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4784377",
   "metadata": {},
   "source": [
    "# Text Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed7b3d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aba3bf00",
   "metadata": {},
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f986130",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
